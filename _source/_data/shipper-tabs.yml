# This YAML feeds the "ship your data" page.
# There are 2 root-level objects: `tabs` and `tags`

# Tabs is an array that contains the collections to be included in the shipping page.
# Each array item is a single entry like this - `collection: <collection-name>`
# The collection name has to match a collection that's declared in Jekyll's _config.yml (in the `collections` object)
# This will support future data types — like traces — when we're ready to make a collection for it.
# So when you're ready to add a collection in the future, follow these steps:
#   1. Add the collection to the config yaml
#   2. Make a folder with the same name in the logzio_collections/ folder
#   3. Add that collection here, in the `tabs` object.
# Keep in mind there are other collections as well, so not all collections are included in this file.

# The community-shippers collection links out to shippers and projects that we don't maintain.

tabs:
  - collection: log-sources
    templated: true
  - collection: prometheus-sources
    templated: true
  - collection: metrics-sources
    templated: true
  - collection: tracing-sources
    templated: true
  - collection: security-sources
    templated: true
  - collection: community-shippers
    top-content: >-
      <p class="info-box important no-title">
        <span class="bold">Logz.io does not test or support these projects.</span><br />
        These projects are maintained by third parties and recommended by members of the Logz.io community.
        Always test and review the code of any community project before using it.
      </p>


# Tags is an array of tags that can be filtered on the data shipping page.
# Each item in the array contains two properties:
#   `slug: <kebab-cased-machine-readable-tag>` (lowercase, dashes only, no other characters)
#   `name: <human readable name for this tag>` (This will be displayed in the docs)
# Tags are used as an ID, so it's best to avoid changing slugs. Users will never see the slug.
# If you want to change the way it's displayed in the docs, change the `name`.

tags:
  - slug: os
    name: Operating systems
  - slug: server-app
    name: Server apps & devices
  - slug: from-your-code
    name: From your code
  - slug: platform-service
    name: Platforms & services
  - slug: aws
    name: AWS
  - slug: azure
    name: Azure
  - slug: gcp
    name: Google Cloud
  - slug: container
    name: Containers & pods
  - slug: ci-cd
    name: CI/CD
  - slug: security
    name: Security
  - slug: database
    name: Databases
  - slug: traces
    name: Tracing
  - slug: networking
    name: Networking
  - slug: agents
    name: Agents
  - slug: vulnerability-scanners
    name: Vulnerability scanners
  - slug: endpoint-security
    name: Endpoint security
  - slug: firewalls
    name: Firewalls
  - slug: k8s
    name: K8S
  - slug: identity
    name: Identity providers
  - slug: linux
    name: Linux security
  - slug: windows
    name: Windows security
  - slug: ids
    name: IDS
  - slug: web-firewalls
    name: Web application firewalls
  - slug: prometheus
    name: Prometheus as a service
  


# templates is an array of rough procedures that are used by multiple shipping
# docs.
# Each item in the array contains two properties:
#   slug: <kebab-cased-machine-readable-tag> (lowercase, dashes only, no other characters)
#   outline: |
#     Starts ^ with a pipe
#     Multiline explanation of the template, and the rough procedure each doc
#     follows. The entire block must be indented two spaces from `outline`.
# This is shown on the docs-admin/data-shipping-templates/ page.

templates:
  - slug: azure-deployment-event-hubs
    outline: |
      **Intro section**: More information

      * What am I setting up in my Azure account?
      * How many automated deployments should I... deploy?

      **Procedure**:

      1. Configure an automated deployment
      1. Set blob container permissions
      1. Build an event subscription
      1. Check Logz.io for your logs

  - slug: beats-logs
    outline: |
      **Procedure**:

      1. [Sometimes] Configure <this source> logging output
      1. Download the Logz.io public certificate
      1. Configure <this source> as an input
      1. Set Logz.io as the output
      1. Restart <shipper>
      1. Check Logz.io for your logs

  - slug: cloudformation
    outline: |
      **Procedure**:

      1. [GuardDuty only] Create a new Kinesis data stream
      1. [GuardDuty only] Configure CloudWatch Events
      1. Zip the source files
      1. Create the CloudFormation package and upload to S3
      1. Deploy the CloudFormation package
      1. Set the CloudWatch Logs event trigger
      1. Check Logz.io for your logs

  - slug: docker
    outline: |
      **Procedure**:

      1. [Okta only] Get credentials
      1. Pull the Docker image
      1. Run the Docker image
      1. Check Logz.io for your logs

  - slug: docker-metricbeat
    outline: |
      **Intro note**:

      If you're not already running Docker Metrics Collector,
      follow these steps.

      Otherwise, stop the container, add
      `<module>`
      to the `LOGZIO_MODULES` environment variable,
      [_Docker module only:_ add `-v /var/run/docker.sock:/var/run/docker.sock:ro` to the command,]
      and restart.
      You can find the `run` command and all parameters
      in this procedure.

      The `<module>` module collects these metrics:
      `<metric 1>`,
      `<metric 2>`,
      `<metric 3>`,
      `<metric 4>`

      **Procedure**:

      1. [AWS module only] Set up your IAM user
      1. [AWS module only] Get your metrics region
      1. [EC2 Auto Scaling only] Enable EC2 Auto Scaling metrics
      1. [S3 only] _(Optional)_ Enable S3 request metrics
      1. Pull the Docker image
      1. Run the container
        (separate headings for generic and module-specific parameters)
      1. Check Logz.io for your metrics
        (include the dashboard name)

  - slug: k8s-daemonset
    outline: |
      **Procedure**:

      1. Store your Logz.io credentials
      1. Deploy the DaemonSet
      1. Check Logz.io for your logs

  - slug: lambda-cloudwatch
    outline: |
      **Procedure**:

      1. Create a new Lambda function
      1. [Sometimes] Create a new IAM Role
      1. Zip the source files
      1. Upload the zip file and set environment variables
      1. Configure the function's basic settings
      1. Set the CloudWatch Logs event trigger
      1. Check Logz.io for your logs


  - slug: lambda-kinesis
    outline: |
      **Procedure**:

      1. [GuardDuty] Create a new Kinesis data stream
      1. [GuardDuty] Configure CloudWatch Events
      1. [GuardDuty] Create a new IAM role
      1. Create a new Lambda function
      1. Zip the source files
      1. Upload the zip file and set environment variables
      1. Configure the function's basic settings
      1. Set the Kinesis event trigger
      1. Check Logz.io for your logs

  - slug: network-device-filebeat
    outline: |
      **Procedure**:

      1. Configure <the device>
      1. Download the Logz.io public certificate to your Filebeat server
      1. Add <UDP/TCP> traffic as an input
      1. Set Logz.io as the output
      1. Start Filebeat
      1. Check Logz.io for your logs

  - slug: s3-fetcher
    outline: |
      **Procedure**:

      1. Send your logs to an S3 bucket
      1. Add the S3 bucket information
      1. Check Logz.io for your logs
